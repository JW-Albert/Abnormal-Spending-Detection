# 消費異常偵測系統

## 系統簡介
本系統可用於消費資料的異常偵測，支援單筆/多筆消費資料輸入，並可自動分析是否有異常消費行為。

## 系統架構與運作流程

### 1. 資料處理流程
1. **資料載入與預處理**
   - 從 `data` 目錄載入所有消費資料
   - 將類別型資料（Location、Item、Category）轉換為數值編碼
   - 日期資料轉換為 datetime 格式

2. **特徵工程**
   - **時域特徵**：計算每個數值欄位的統計量
     - RMS（均方根值）
     - 平均值
     - 標準差
     - 峰峰值（Peak-to-Peak）
     - 峰度（Kurtosis）
     - 偏度（Skewness）
   
   - **頻域特徵**：使用 FFT 進行頻譜分析
     - 計算主要頻率成分的振幅
     - 分析不同頻率區間的訊號強度

3. **資料標準化與降維**
   - 使用 StandardScaler 進行特徵標準化
   - 應用 PCA 進行維度降低
   - 使用 LDA 進行監督式降維

### 2. 異常偵測模型

1. **Hotelling's T² 統計量**
   - 原理：計算樣本點到主成分空間的馬氏距離
   - 用途：檢測樣本是否偏離正常分布
   - 閾值：使用 95% 分位數作為異常判定標準

2. **SPE（Squared Prediction Error）**
   - 原理：計算原始資料與重建資料的誤差平方和
   - 用途：檢測模型無法解釋的變異
   - 閾值：同樣使用 95% 分位數

3. **One-Class SVM**
   - 原理：在特徵空間中建立一個超平面，將正常樣本與原點分開
   - 特點：適合處理高維資料，對異常樣本敏感

4. **Isolation Forest**
   - 原理：隨機選擇特徵和切分點，建立決策樹
   - 特點：計算效率高，適合處理大規模資料

5. **邏輯回歸（Logistic Regression）**
   - 用途：作為基準模型，評估特徵的有效性
   - 特點：可解釋性強，訓練速度快

### 3. 模型評估與視覺化

1. **評估指標**
   - 準確率（Accuracy）
   - 精確率（Precision）
   - 召回率（Recall）
   - F1 分數
   - ROC 曲線與 AUC 值

2. **視覺化輸出**
   - 每日消費比較圖
   - PCA 投影圖
   - LDA 視覺化
   - 時域特徵分布圖
   - 頻域特徵分布圖
   - 模型比較圖表

### 4. 系統輸出
- 所有圖表保存在 `img` 目錄
- 處理後的資料保存在 `data/merged.csv`
- 模型評估報告包含詳細的分類指標

---

## 模型成效分析與改善建議

### 1. 分類報表（classification_report）

```
              precision    recall  f1-score   support

           0     1.0000    1.0000    1.0000         1
           1     1.0000    1.0000    1.0000        21

    accuracy                         1.0000        22
   macro avg     1.0000    1.0000    1.0000        22
weighted avg     1.0000    1.0000    1.0000        22
```

- 這是邏輯回歸（Logistic Regression）在測試集上的結果，精確率、召回率、F1分數都為1。
- 但 abnormal（0）只有 1 筆，normal（1）有 21 筆，資料極度不平衡。
- 這種情況下，模型只要預測全為 normal 也能拿到高分，**不代表模型真的有辨識異常的能力**。

### 2. 各異常偵測模型比較

```
                  Accuracy  Precision    Recall        F1
Hotelling T²      0.028302   0.166667  0.010101  0.019048
SPE               0.084906   0.666667  0.040404  0.076190
One-Class SVM     0.009434   0.000000  0.000000  0.000000
Isolation Forest  0.028302   0.166667  0.010101  0.019048
```
- 所有異常偵測模型的準確率都極低，F1分數也接近0。
- 代表這些模型在目前資料下，**無法有效分辨異常與正常**。
- One-Class SVM 完全無法抓到異常（Precision/Recall/F1 全為0）。

### 3. 圖片分析（img 資料夾）

- `daily_spending.png`：顯示正常/異常每日消費金額分布。若紅藍線高度重疊，代表異常與正常消費行為在金額上差異不大，模型難以分辨。
- `pca_projection.png`、`lda_visualization.png`：降維後的資料分布。若異常（紅色）與正常（藍色）點分布混雜，代表特徵無法有效分群，模型難以學習。
- `ocsvm_scores.png`、`iso_forest_scores.png`：異常分數分布。若大多數資料分數接近，且異常樣本沒有明顯高分，代表模型無法區分異常。
- `model_comparison.png`：各模型的準確率、精確率、召回率、F1分數條狀圖。可以一目了然看到所有模型表現都很差。

### 4. 綜合結論

1. **目前資料特徵無法有效區分異常與正常**，不論是監督式（Logistic Regression）還是無監督異常偵測（OCSVM、Isolation Forest等）都無法得到好結果。
2. 主要原因可能是：
   - 異常樣本太少，且與正常樣本特徵分布高度重疊。
   - 特徵工程（如時域、頻域特徵）無法反映異常行為的本質差異。
   - 樣本不平衡問題嚴重。

### 5. 改善建議

- **增加異常樣本數量**，或嘗試合成異常資料（如 SMOTE、資料擴增等）。
- **重新檢視特徵設計**，找出更能反映異常消費行為的特徵。
- 可考慮用更複雜的模型（如深度學習），但前提還是要有足夠且有意義的異常資料。
- 若有 domain knowledge，可嘗試設計規則型特徵或專家系統輔助。

---

如需針對每張圖做更細緻的說明，或想討論資料/特徵如何優化，請參考 img 資料夾內的圖檔，或聯絡開發者。 